{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bb83e4",
   "metadata": {},
   "source": [
    "# Result - Analysis Debugging Validation Experiment\n",
    "\n",
    "This experiment focuses on validating the effectiveness of analysis debugging techniques. The goal is to ensure that the implemented debugging methods accurately can acheive a good recall with datamodels and be performatic. Every step of the experiment is evaluated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee02605e",
   "metadata": {},
   "source": [
    "## Main Results\n",
    "\n",
    "* RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c440039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from experiments.prompt_analysis_recall.run_rag import INSTRUCTIONS\n",
    "from utils.metrics.calculate_metric import calculate_agg_metric\n",
    "\n",
    "EXPERIMENTS = [\"experiment_1\", \"experiment_4\", \"experiment_54\", \"experiment_61\", \"experiment_73\"]\n",
    "INSTRUCTIONS = [\"instruction_0\", \"instruction_1\", \"instruction_2\"]\n",
    "ROOT = \"..\"\n",
    "\n",
    "wiki = pl.read_ipc(f\"../../../data/wiki_dump2018_nq_open/processed/wiki.feather\")\n",
    "gold = pl.read_ipc(f\"../../../data/nq_open_gold/processed/dev.feather\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad8aa0",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each experiment, calculate rouge_l metric for each questions\n",
    "\n",
    "LOAD = True\n",
    "\n",
    "if not LOAD:\n",
    "\n",
    "    rag_dfs_generations = []\n",
    "    for exp in EXPERIMENTS:\n",
    "        for inst in INSTRUCTIONS:\n",
    "            questions_path = f\"{ROOT}/{exp}/questions.feather\"\n",
    "            for file in os.listdir(f\"{ROOT}/{exp}/{inst}/generations\"):\n",
    "                    if file.startswith(\"rag_\"):\n",
    "                        rag_dfs_generations.append(calculate_agg_metric(\n",
    "                            metrics=[\"rouge_l\"],\n",
    "                            generation_path=f\"{ROOT}/{exp}/{inst}/generations/{file}\",\n",
    "                            reference_path=questions_path    ,\n",
    "                            saving_path=None            \n",
    "                        )\n",
    "                        .with_columns([\n",
    "                            pl.lit(exp).alias(\"experiment\"),\n",
    "                            pl.lit(inst).alias(\"instruction\")\n",
    "                        ]))\n",
    "\n",
    "    rag_dfs_generations = pl.concat(rag_dfs_generations)\n",
    "    rag_dfs_generations.write_ipc(f\"rag_dfs_generations.feather\")        \n",
    "else:\n",
    "    rag_dfs_generations = pl.read_ipc(f\"rag_dfs_generations.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d38a0861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>experiment</th><th>instruction</th><th>mean</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;experiment_1&quot;</td><td>&quot;instruction_0&quot;</td><td>0.084784</td></tr><tr><td>&quot;experiment_1&quot;</td><td>&quot;instruction_1&quot;</td><td>0.110382</td></tr><tr><td>&quot;experiment_1&quot;</td><td>&quot;instruction_2&quot;</td><td>0.072232</td></tr><tr><td>&quot;experiment_4&quot;</td><td>&quot;instruction_0&quot;</td><td>0.060617</td></tr><tr><td>&quot;experiment_4&quot;</td><td>&quot;instruction_1&quot;</td><td>0.098221</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;experiment_61&quot;</td><td>&quot;instruction_1&quot;</td><td>0.10138</td></tr><tr><td>&quot;experiment_61&quot;</td><td>&quot;instruction_2&quot;</td><td>0.066447</td></tr><tr><td>&quot;experiment_73&quot;</td><td>&quot;instruction_0&quot;</td><td>0.073177</td></tr><tr><td>&quot;experiment_73&quot;</td><td>&quot;instruction_1&quot;</td><td>0.099507</td></tr><tr><td>&quot;experiment_73&quot;</td><td>&quot;instruction_2&quot;</td><td>0.070951</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 3)\n",
       "┌───────────────┬───────────────┬──────────┐\n",
       "│ experiment    ┆ instruction   ┆ mean     │\n",
       "│ ---           ┆ ---           ┆ ---      │\n",
       "│ str           ┆ str           ┆ f64      │\n",
       "╞═══════════════╪═══════════════╪══════════╡\n",
       "│ experiment_1  ┆ instruction_0 ┆ 0.084784 │\n",
       "│ experiment_1  ┆ instruction_1 ┆ 0.110382 │\n",
       "│ experiment_1  ┆ instruction_2 ┆ 0.072232 │\n",
       "│ experiment_4  ┆ instruction_0 ┆ 0.060617 │\n",
       "│ experiment_4  ┆ instruction_1 ┆ 0.098221 │\n",
       "│ …             ┆ …             ┆ …        │\n",
       "│ experiment_61 ┆ instruction_1 ┆ 0.10138  │\n",
       "│ experiment_61 ┆ instruction_2 ┆ 0.066447 │\n",
       "│ experiment_73 ┆ instruction_0 ┆ 0.073177 │\n",
       "│ experiment_73 ┆ instruction_1 ┆ 0.099507 │\n",
       "│ experiment_73 ┆ instruction_2 ┆ 0.070951 │\n",
       "└───────────────┴───────────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dfs_generations.group_by([\"experiment\", \"instruction\"]).agg(pl.mean(\"mean\")).sort([\"experiment\", \"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62d31291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: experiment_1 - Gold founds: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: experiment_4 - Gold founds: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: experiment_54 - Gold founds: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: experiment_61 - Gold founds: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: experiment_73 - Gold founds: 0\n"
     ]
    }
   ],
   "source": [
    "## gold per retrieval\n",
    "ROOT = \"\"\n",
    "for exp in EXPERIMENTS:\n",
    "    _path = f\"{exp}\"\n",
    "    docs_to_retrieve = json.load(open(f\"{_path}/instruction_0/retrieval/rag_retrieval_indexes.json\", \"r\"))\n",
    "    questions = pl.read_ipc(f\"{_path}/questions.feather\")\n",
    "    count = 0\n",
    "    for i in range(500):\n",
    "        for idx in docs_to_retrieve[str(i)]:\n",
    "            if idx == gold.filter(pl.col(\"idx\") == questions[i][\"idx\"].to_list()[0])[\"idx_gold_in_corpus\"].to_list()[0]:\n",
    "                count += 1\n",
    "    print(f\"Experiment: {exp} - Gold founds: {count}\")\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a6d7b",
   "metadata": {},
   "source": [
    "## Datamodels Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not memory_map compressed IPC file, defaulting to normal read. Toggle off 'memory_map' to silence this warning.\n",
      "WARNING:evaluate.loading:Using the latest cached version of the module from /home/caio.rhoden/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--rouge/b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Wed Oct 16 22:50:24 2024) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "LOAD = True\n",
    "\n",
    "if not LOAD:\n",
    "    \n",
    "    datamodels_dfs_generations = []\n",
    "    for exp in EXPERIMENTS:\n",
    "        for inst in INSTRUCTIONS:\n",
    "            questions_path = f\"{ROOT}/{exp}/questions.feather\"\n",
    "            for file in os.listdir(f\"{ROOT}/{exp}/{inst}/generations\"):\n",
    "                    if file.startswith(\"instruction\"):\n",
    "                        datamodels_dfs_generations.append(calculate_agg_metric(\n",
    "                            metrics=[\"rouge_l\"],\n",
    "                            generation_path=f\"{ROOT}/{exp}/{inst}/generations/{file}\",\n",
    "                            reference_path=questions_path    ,\n",
    "                            saving_path=None            \n",
    "                        )\n",
    "                        .with_columns([\n",
    "                            pl.lit(exp).alias(\"experiment\"),\n",
    "                            pl.lit(inst).alias(\"instruction\")\n",
    "                        ]))\n",
    "                \n",
    "\n",
    "    datamodels_dfs_generations = pl.concat(datamodels_dfs_generations)\n",
    "    datamodels_dfs_generations.write_ipc(f\"datamodels_dfs_generations.feather\")        \n",
    "else:\n",
    "    datamodels_dfs_generations = pl.read_ipc(f\"datamodels_dfs_generations.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aed4bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>experiment</th><th>instruction</th><th>mean</th></tr><tr><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;experiment_1&quot;</td><td>&quot;instruction_0&quot;</td><td>0.115352</td></tr><tr><td>&quot;experiment_4&quot;</td><td>&quot;instruction_0&quot;</td><td>0.108255</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌──────────────┬───────────────┬──────────┐\n",
       "│ experiment   ┆ instruction   ┆ mean     │\n",
       "│ ---          ┆ ---           ┆ ---      │\n",
       "│ str          ┆ str           ┆ f64      │\n",
       "╞══════════════╪═══════════════╪══════════╡\n",
       "│ experiment_1 ┆ instruction_0 ┆ 0.115352 │\n",
       "│ experiment_4 ┆ instruction_0 ┆ 0.108255 │\n",
       "└──────────────┴───────────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodels_dfs_generations.group_by([\"experiment\", \"instruction\"]).agg(pl.mean(\"mean\")).sort([\"experiment\", \"instruction\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
