saving_paths:
  inference: "inference/no_context_baseline"
  results: "results/no_context_baseline"

inference_configs:
  instruction: "You are given a question and you MUST respond in 5 tokens"
  model_path: "../models/llms/Llama-3.2-3B-Instruct"
  log_datetime: False
  quantization: True
  start_idx: 0
  end_idx: 6

model_configs:
  temperature: 0.7
  top_p: 0.95
  max_length: 2048
  max_new_tokens: 10

runtime_configs:
  debug: True
  skip_inference: False
  skip_results: False
  wiki_path: "../data/wiki_dump2018_nq_open/processed/wiki.feather"
  questions_path: "../data/nq_open_gold/processed/train.feather"
  
wandb_configs:
  project: "nq_small_sampling_experiment"
  experiment_name: "no_context_baseline"
  wandb_dir: "logs"