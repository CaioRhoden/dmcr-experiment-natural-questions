{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1761fc8",
   "metadata": {},
   "source": [
    "# Performance Results\n",
    "\n",
    "The goal here is to compare the performance results with different contexts:\n",
    "- Baseline (No Context)\n",
    "- RAG all Wikipedia (FAISS)\n",
    "- RAG selected samples\n",
    "- Datamodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c5f73",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- [Load Data]()\n",
    "- [Create FAISS]()\n",
    "- [Create different contexts]()\n",
    "- [Run Inferences]()\n",
    "- [Compare Results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3897b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "seed = 42\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "# NumPy\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce443df7",
   "metadata": {
    "tags": [
     "load_data"
    ]
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef556700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['when did the who perform at the super bowl',\n",
       "       'why was there so much interest in cuba both before and after the civil war',\n",
       "       'who developed the first periodic table with 8 columns',\n",
       "       'the organization of the formal elements in an art work',\n",
       "       'where did the french king live before versailles'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Questions\n",
    "\n",
    "questions = []\n",
    "for i in range(5):\n",
    "    questions.append(pl.read_csv(f\"question_{i}_datamodels/test_set.csv\"))\n",
    "\n",
    "questions = pl.concat(questions)\n",
    "questions.select(\"question\").to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d982979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1861859/2729841633.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(f\"question_{i}_datamodels/models/regression_question_{i}/weights.pt\").to(\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>text</th><th>title</th><th>idx_right</th><th>question_id</th><th>weights</th><th>is_from_same_page</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>0</td><td>&quot;Date : Feb 5 , 2017 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>0.038918</td><td>true</td></tr><tr><td>1</td><td>&quot;Date : Feb 4 , 2018 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.15716</td><td>true</td></tr><tr><td>2</td><td>&quot;Date : Feb 3 , 2013 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.050358</td><td>true</td></tr><tr><td>3</td><td>&quot;The NFL does not pay the halft…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.164697</td><td>true</td></tr><tr><td>4</td><td>&quot;LI Main article : Super Bowl L…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.113502</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────┬──────────────────┬─────────────────┬───────────┬─────────────┬───────────┬─────────────────┐\n",
       "│ idx ┆ text             ┆ title           ┆ idx_right ┆ question_id ┆ weights   ┆ is_from_same_pa │\n",
       "│ --- ┆ ---              ┆ ---             ┆ ---       ┆ ---         ┆ ---       ┆ ge              │\n",
       "│ i64 ┆ str              ┆ str             ┆ i64       ┆ str         ┆ f64       ┆ ---             │\n",
       "│     ┆                  ┆                 ┆           ┆             ┆           ┆ bool            │\n",
       "╞═════╪══════════════════╪═════════════════╪═══════════╪═════════════╪═══════════╪═════════════════╡\n",
       "│ 0   ┆ Date : Feb 5 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ 0.038918  ┆ true            │\n",
       "│     ┆ 2017 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 1   ┆ Date : Feb 4 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.15716  ┆ true            │\n",
       "│     ┆ 2018 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 2   ┆ Date : Feb 3 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.050358 ┆ true            │\n",
       "│     ┆ 2013 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 3   ┆ The NFL does not ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.164697 ┆ true            │\n",
       "│     ┆ pay the halft…   ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 4   ┆ LI Main article  ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.113502 ┆ true            │\n",
       "│     ┆ : Super Bowl L…  ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "└─────┴──────────────────┴─────────────────┴───────────┴─────────────┴───────────┴─────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train samples\n",
    "train_sets = []\n",
    "for i in range(5):\n",
    "    train_sets.append(pl.read_csv(f\"question_{i}_datamodels/train_set.csv\").with_columns(pl.lit(f\"question_{i}\").alias(\"question_id\")))\n",
    "train = pl.concat(train_sets)\n",
    "\n",
    "### Load weights\n",
    "weights_set = []\n",
    "for i in range(5):\n",
    "    weights = torch.load(f\"question_{i}_datamodels/models/regression_question_{i}/weights.pt\").to(\"cpu\")\n",
    "    weights_set.append(weights)\n",
    "\n",
    "## add weights to sample training\n",
    "list_weights = []\n",
    "for set in weights_set:\n",
    "    for _w in set[0]:\n",
    "        list_weights.append(float(_w.item()))\n",
    "\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.Series(\"weights\", list_weights),\n",
    "    pl.when(pl.col(\"idx_right\").is_not_null())\n",
    "        .then(True)\n",
    "        .otherwise(False)\n",
    "        .alias(\"is_from_same_page\")\n",
    "\n",
    ")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde04a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>text</th><th>title</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Aaron Aaron ( or ; &quot;Ahärôn&quot;) i…</td><td>&quot;Aaron&quot;</td></tr><tr><td>1</td><td>&quot;God at Sinai granted Aaron the…</td><td>&quot;Aaron&quot;</td></tr><tr><td>2</td><td>&quot;his rod turn into a snake. The…</td><td>&quot;Aaron&quot;</td></tr><tr><td>3</td><td>&quot;however, Aaron and Hur remaine…</td><td>&quot;Aaron&quot;</td></tr><tr><td>4</td><td>&quot;Aaron and his sons to the prie…</td><td>&quot;Aaron&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────┬─────────────────────────────────┬───────┐\n",
       "│ idx ┆ text                            ┆ title │\n",
       "│ --- ┆ ---                             ┆ ---   │\n",
       "│ u32 ┆ str                             ┆ str   │\n",
       "╞═════╪═════════════════════════════════╪═══════╡\n",
       "│ 0   ┆ Aaron Aaron ( or ; \"Ahärôn\") i… ┆ Aaron │\n",
       "│ 1   ┆ God at Sinai granted Aaron the… ┆ Aaron │\n",
       "│ 2   ┆ his rod turn into a snake. The… ┆ Aaron │\n",
       "│ 3   ┆ however, Aaron and Hur remaine… ┆ Aaron │\n",
       "│ 4   ┆ Aaron and his sons to the prie… ┆ Aaron │\n",
       "└─────┴─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Wiki\n",
    "WIKI_PATH = \"../../data/wiki_dump2018_nq_open/processed/wiki.feather\"\n",
    "wiki = pl.read_ipc(WIKI_PATH).with_row_index(\"idx\")\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48038053",
   "metadata": {},
   "source": [
    "## Create FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c9f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/nq/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import faiss\n",
    "from tqdm import tqdm  \n",
    "\n",
    "EMBERDDER_PATH = \"../../models/llms/bge-base-en-v1.5\"\n",
    "embedder = FlagModel(EMBERDDER_PATH, devices=[\"cuda:0\"], use_fp16=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee04d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = faiss.IndexFlatIP(768)\n",
    "index = faiss.read_index(\"wiki.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b59dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total_size = len(wiki)\n",
    "# batch_size = 80000\n",
    "# torch.backends.cuda.enable_cudnn_sdp(False)\n",
    "\n",
    "# for start in range(5200000, total_size, batch_size):\n",
    "    \n",
    "#     end = min(start + batch_size, total_size)\n",
    "#     print(f\"End: {end}\")\n",
    "    \n",
    "#     batch_texts = wiki[start:end].select(\"text\").to_numpy().flatten().tolist()\n",
    "    \n",
    "#     # Encode the current batch\n",
    "#     batch_embeddings = embedder.encode(\n",
    "#         batch_texts,\n",
    "#         convert_to_numpy=True,\n",
    "#     )\n",
    "    \n",
    "#     # Add to index\n",
    "#     index.add(batch_embeddings.astype('float32'))\n",
    "#     faiss.write_index(index, \"wiki.index\")\n",
    "\n",
    "    \n",
    "#     # Optional: Clear memory if needed\n",
    "#     del batch_texts, batch_embeddings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Demo FAISS search\n",
    "questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
