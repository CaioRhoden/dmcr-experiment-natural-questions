{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1761fc8",
   "metadata": {},
   "source": [
    "# Performance Results\n",
    "\n",
    "The goal here is to compare the performance results with different contexts:\n",
    "- Baseline (No Context)\n",
    "- RAG all Wikipedia (FAISS)\n",
    "- RAG selected samples\n",
    "- Datamodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c5f73",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- [Load Data]()\n",
    "- [Create FAISS]()\n",
    "- [Create different contexts]()\n",
    "- [Run Inferences]()\n",
    "- [Compare Results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3897b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "seed = 42\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "# NumPy\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce443df7",
   "metadata": {
    "tags": [
     "load_data"
    ]
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef556700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['when did the who perform at the super bowl',\n",
       "       'why was there so much interest in cuba both before and after the civil war',\n",
       "       'who developed the first periodic table with 8 columns',\n",
       "       'the organization of the formal elements in an art work',\n",
       "       'where did the french king live before versailles'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Questions\n",
    "\n",
    "questions = []\n",
    "for i in range(5):\n",
    "    questions.append(pl.read_csv(f\"question_{i}_datamodels/test_set.csv\"))\n",
    "\n",
    "questions = pl.concat(questions)\n",
    "questions.select(\"question\").to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d982979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2849775/2729841633.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(f\"question_{i}_datamodels/models/regression_question_{i}/weights.pt\").to(\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>text</th><th>title</th><th>idx_right</th><th>question_id</th><th>weights</th><th>is_from_same_page</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>bool</td></tr></thead><tbody><tr><td>0</td><td>&quot;Date : Feb 5 , 2017 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>0.038918</td><td>true</td></tr><tr><td>1</td><td>&quot;Date : Feb 4 , 2018 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.15716</td><td>true</td></tr><tr><td>2</td><td>&quot;Date : Feb 3 , 2013 Location :…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.050358</td><td>true</td></tr><tr><td>3</td><td>&quot;The NFL does not pay the halft…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.164697</td><td>true</td></tr><tr><td>4</td><td>&quot;LI Main article : Super Bowl L…</td><td>&quot;List of Super Bowl halftime sh…</td><td>20970820</td><td>&quot;question_0&quot;</td><td>-0.113502</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────┬──────────────────┬─────────────────┬───────────┬─────────────┬───────────┬─────────────────┐\n",
       "│ idx ┆ text             ┆ title           ┆ idx_right ┆ question_id ┆ weights   ┆ is_from_same_pa │\n",
       "│ --- ┆ ---              ┆ ---             ┆ ---       ┆ ---         ┆ ---       ┆ ge              │\n",
       "│ i64 ┆ str              ┆ str             ┆ i64       ┆ str         ┆ f64       ┆ ---             │\n",
       "│     ┆                  ┆                 ┆           ┆             ┆           ┆ bool            │\n",
       "╞═════╪══════════════════╪═════════════════╪═══════════╪═════════════╪═══════════╪═════════════════╡\n",
       "│ 0   ┆ Date : Feb 5 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ 0.038918  ┆ true            │\n",
       "│     ┆ 2017 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 1   ┆ Date : Feb 4 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.15716  ┆ true            │\n",
       "│     ┆ 2018 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 2   ┆ Date : Feb 3 ,   ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.050358 ┆ true            │\n",
       "│     ┆ 2013 Location :… ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 3   ┆ The NFL does not ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.164697 ┆ true            │\n",
       "│     ┆ pay the halft…   ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "│ 4   ┆ LI Main article  ┆ List of Super   ┆ 20970820  ┆ question_0  ┆ -0.113502 ┆ true            │\n",
       "│     ┆ : Super Bowl L…  ┆ Bowl halftime   ┆           ┆             ┆           ┆                 │\n",
       "│     ┆                  ┆ sh…             ┆           ┆             ┆           ┆                 │\n",
       "└─────┴──────────────────┴─────────────────┴───────────┴─────────────┴───────────┴─────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train samples\n",
    "train_sets = []\n",
    "for i in range(5):\n",
    "    train_sets.append(pl.read_csv(f\"question_{i}_datamodels/train_set.csv\").with_columns(pl.lit(f\"question_{i}\").alias(\"question_id\")))\n",
    "train = pl.concat(train_sets)\n",
    "\n",
    "### Load weights\n",
    "weights_set = []\n",
    "for i in range(5):\n",
    "    weights = torch.load(f\"question_{i}_datamodels/models/regression_question_{i}/weights.pt\").to(\"cpu\")\n",
    "    weights_set.append(weights)\n",
    "\n",
    "## add weights to sample training\n",
    "list_weights = []\n",
    "for set in weights_set:\n",
    "    for _w in set[0]:\n",
    "        list_weights.append(float(_w.item()))\n",
    "\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.Series(\"weights\", list_weights),\n",
    "    pl.when(pl.col(\"idx_right\").is_not_null())\n",
    "        .then(True)\n",
    "        .otherwise(False)\n",
    "        .alias(\"is_from_same_page\")\n",
    "\n",
    ")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde04a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>idx</th><th>text</th><th>title</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Aaron Aaron ( or ; &quot;Ahärôn&quot;) i…</td><td>&quot;Aaron&quot;</td></tr><tr><td>1</td><td>&quot;God at Sinai granted Aaron the…</td><td>&quot;Aaron&quot;</td></tr><tr><td>2</td><td>&quot;his rod turn into a snake. The…</td><td>&quot;Aaron&quot;</td></tr><tr><td>3</td><td>&quot;however, Aaron and Hur remaine…</td><td>&quot;Aaron&quot;</td></tr><tr><td>4</td><td>&quot;Aaron and his sons to the prie…</td><td>&quot;Aaron&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────┬─────────────────────────────────┬───────┐\n",
       "│ idx ┆ text                            ┆ title │\n",
       "│ --- ┆ ---                             ┆ ---   │\n",
       "│ u32 ┆ str                             ┆ str   │\n",
       "╞═════╪═════════════════════════════════╪═══════╡\n",
       "│ 0   ┆ Aaron Aaron ( or ; \"Ahärôn\") i… ┆ Aaron │\n",
       "│ 1   ┆ God at Sinai granted Aaron the… ┆ Aaron │\n",
       "│ 2   ┆ his rod turn into a snake. The… ┆ Aaron │\n",
       "│ 3   ┆ however, Aaron and Hur remaine… ┆ Aaron │\n",
       "│ 4   ┆ Aaron and his sons to the prie… ┆ Aaron │\n",
       "└─────┴─────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load Wiki\n",
    "WIKI_PATH = \"../../data/wiki_dump2018_nq_open/processed/wiki.feather\"\n",
    "wiki = pl.read_ipc(WIKI_PATH).with_row_index(\"idx\")\n",
    "wiki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ad805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "random = []\n",
    "for i in range(5):\n",
    "    target_i = pl.read_ipc(f\"question_{i}_datamodels/target.feather\").with_columns(pl.lit(f\"question_{i}\").alias(\"question_id\"))\n",
    "    random_i = pl.read_ipc(f\"question_{i}_datamodels/random.feather\").with_columns(pl.lit(f\"question_{i}\").alias(\"question_id\"))\n",
    "    target.append(target_i)\n",
    "    random.append(random_i)\n",
    "\n",
    "target = pl.concat(target)\n",
    "random = pl.concat(random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48038053",
   "metadata": {},
   "source": [
    "## Create FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c9f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/nq/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "import faiss\n",
    "from tqdm import tqdm  \n",
    "\n",
    "EMBERDDER_PATH = \"../../models/llms/bge-base-en-v1.5\"\n",
    "embedder = FlagModel(EMBERDDER_PATH, devices=[\"cuda:0\"], use_fp16=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee04d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexScalarQuantizer(768, 8)\n",
    "# index = faiss.read_index(\"wiki.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b59dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 313/313 [00:07<00:00, 40.88it/s]\n",
      "Inference Embeddings: 100%|██████████| 313/313 [00:36<00:00,  8.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_size = len(wiki)\n",
    "batch_size = 80000\n",
    "torch.backends.cuda.enable_cudnn_sdp(False)\n",
    "\n",
    "for start in range(80000, total_size, batch_size):\n",
    "    \n",
    "    end = min(start + batch_size, total_size)\n",
    "    print(f\"End: {end}\")\n",
    "    \n",
    "    batch_texts = wiki[start:end].select(\"text\").to_numpy().flatten().tolist()\n",
    "    \n",
    "    # Encode the current batch\n",
    "    batch_embeddings = embedder.encode(\n",
    "        batch_texts,\n",
    "        convert_to_numpy=True,\n",
    "    )\n",
    "    \n",
    "    # Add to index\n",
    "    index.add(batch_embeddings.astype('float32'))\n",
    "    faiss.write_index(index, \"wiki.index\")\n",
    "\n",
    "    \n",
    "    # Optional: Clear memory if needed\n",
    "    del batch_texts, batch_embeddings\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f71d7f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why was there so much interest in cuba both before and after the civil war'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[1][\"question\"].to_numpy().flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5fb5264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "### Demo FAISS search\n",
    "test_query = questions[1][\"question\"].to_numpy().flatten()[0]\n",
    "query_embedding = embedder.encode(\n",
    "    [test_query],\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "query_embedding = query_embedding.astype('float32').reshape(1, -1)\n",
    "distances, indices = index.search(query_embedding, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7853d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[15107718, 11485636,   380206,   380167]]),\n",
       " array([[0.7561871 , 0.7198814 , 0.71146166, 0.7023028 ]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "indices, distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069850c3",
   "metadata": {},
   "source": [
    "## Create Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "288db6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:05<00:20,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [[0.8165758  0.801557   0.7908786  0.78759444]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:10<00:16,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [[0.7561871  0.7198814  0.71146166 0.7023028 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:16<00:11,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [[0.8041481  0.8028399  0.78939456 0.78801113]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:22<00:14,  7.46s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 21409643 is out of bounds for DataFrame of height 21035236",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m query_embedding = query_embedding.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m).reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     12\u001b[39m distances, indices = index.search(query_embedding, \u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m faiss_context[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = \u001b[43m[\u001b[49m\u001b[43mwiki\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     11\u001b[39m query_embedding = query_embedding.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m).reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     12\u001b[39m distances, indices = index.search(query_embedding, \u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m faiss_context[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = [\u001b[43mwiki\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m].to_numpy().flatten()[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m indices[\u001b[32m0\u001b[39m]]\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistances\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nq/lib/python3.11/site-packages/polars/dataframe/frame.py:1362\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     key: (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1236\u001b[39m     ),\n\u001b[32m   1237\u001b[39m ) -> DataFrame | Series | Any:\n\u001b[32m   1238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1239\u001b[39m \u001b[33;03m    Get part of the DataFrame as a new DataFrame, Series, or scalar.\u001b[39;00m\n\u001b[32m   1240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1360\u001b[39m \u001b[33;03m    └─────┴─────┴─────┘\u001b[39;00m\n\u001b[32m   1361\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_df_item_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nq/lib/python3.11/site-packages/polars/_utils/getitem.py:167\u001b[39m, in \u001b[36mget_df_item_by_key\u001b[39m\u001b[34m(df, key)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Single input - df[1] - or multiple inputs - df[\"a\", \"b\", \"c\"]\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _select_columns(df, key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nq/lib/python3.11/site-packages/polars/_utils/getitem.py:297\u001b[39m, in \u001b[36m_select_rows\u001b[39m\u001b[34m(df, key)\u001b[39m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (key >= num_rows) \u001b[38;5;129;01mor\u001b[39;00m (key < -num_rows):\n\u001b[32m    296\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is out of bounds for DataFrame of height \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(msg)\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.slice(key, \u001b[32m1\u001b[39m)\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n",
      "\u001b[31mIndexError\u001b[39m: index 21409643 is out of bounds for DataFrame of height 21035236"
     ]
    }
   ],
   "source": [
    "### FAISS context\n",
    "faiss_context = {}\n",
    "\n",
    "for i in tqdm(range(len(questions))):\n",
    "\n",
    "    question = questions[i][\"question\"].to_numpy().flatten()[0]\n",
    "    query_embedding = embedder.encode(\n",
    "        [question],\n",
    "        convert_to_numpy=True,\n",
    "    )\n",
    "    query_embedding = query_embedding.astype('float32').reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, 4)\n",
    "\n",
    "    faiss_context[f\"question_{i}\"] = [wiki[int(j)][\"text\"].to_numpy().flatten()[0] for j in indices[0]]\n",
    "    print(f\"Scores: {distances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39707b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "datamodels_general_context = {}\n",
    "for i in tqdm(range(len(questions))):\n",
    "    weights = train.filter(pl.col(\"question_id\") == f\"question_{i}\").select(\"\").to_numpy().flatten()[0]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
